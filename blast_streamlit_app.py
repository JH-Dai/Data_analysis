import streamlit as st
import pandas as pd
import os
import io

st.set_page_config(page_title="BLASTç­›é€‰å·¥å…·", layout="wide")
st.title("ðŸ§¬ BLAST ç»“æžœåˆ†æžå·¥å…·ï¼ˆä¸Šä¼  + æ‹†åˆ† + ç­›é€‰ + ä¸‹è½½ï¼‰")

UPLOAD_DIR = "uploaded"
SPLIT_DIR = "split_queries"
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(SPLIT_DIR, exist_ok=True)

# ä¼šè¯çŠ¶æ€
if "results_ready" not in st.session_state:
    st.session_state.results_ready = False
if "global_result_df" not in st.session_state:
    st.session_state.global_result_df = pd.DataFrame()
if "total_hits" not in st.session_state:
    st.session_state.total_hits = 0
if "skipped_queries" not in st.session_state:
    st.session_state.skipped_queries = []

# ä¸Šä¼  + æ‹†åˆ†
uploaded_file = st.file_uploader("ðŸ“¤ è¯·ä¸Šä¼  BLASTN ç»“æžœæ–‡ä»¶ï¼ˆå« `# Query:` è¡Œï¼‰", type=["txt", "tsv"])

def split_file(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        current_block = []
        query_id = None
        block_count = 0
        for line in f:
            if line.startswith("# Query:"):
                if current_block and query_id:
                    out_path = os.path.join(SPLIT_DIR, f"{query_id}.txt")
                    with open(out_path, "w", encoding="utf-8") as out:
                        out.writelines(current_block)
                    block_count += 1
                query_id = line.strip().split(":")[1].strip().replace("/", "_")
                current_block = [line]
            else:
                current_block.append(line)
        if current_block and query_id:
            out_path = os.path.join(SPLIT_DIR, f"{query_id}.txt")
            with open(out_path, "w", encoding="utf-8") as out:
                out.writelines(current_block)
            block_count += 1
    return block_count

if uploaded_file is not None:
    file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    st.success(f"âœ… æ–‡ä»¶å·²ä¸Šä¼ ï¼š{uploaded_file.name}")
    count = split_file(file_path)
    st.success(f"ðŸ”§ å·²æˆåŠŸæ‹†åˆ†ä¸º {count} ä¸ª query blocksï¼Œå­˜æ”¾äºŽ `{SPLIT_DIR}/`")

# æŸ¥è¯¢åˆ—è¡¨
query_files = sorted([f for f in os.listdir(SPLIT_DIR) if f.endswith(".txt")])
if not query_files:
    st.info("ðŸ“­ å½“å‰æ—  query æ•°æ®ï¼Œè¯·å…ˆä¸Šä¼  BLAST ç»“æžœæ–‡ä»¶ã€‚")
    st.stop()

# è¯»å– query æ–‡ä»¶
def load_query_file(filepath):
    with open(filepath, 'r', encoding="utf-8") as f:
        lines = f.readlines()
    data_lines = [line for line in lines if not line.startswith("#") and line.strip()]
    if not data_lines:
        return pd.DataFrame(), lines
    df = pd.read_csv(io.StringIO("".join(data_lines)), sep="\t", header=None)
    df.columns = [
        "query", "subject", "identity", "alignment_length", "mismatches", "gap_opens",
        "q_start", "q_end", "s_start", "s_end", "evalue", "bit_score"
    ]
    df = df.apply(pd.to_numeric, errors="ignore")
    return df, lines

# ç­›é€‰å‡½æ•°
def apply_filter_to_all_queries(params):
    all_results = []
    total_hits = 0
    skipped = []
    for qfile in os.listdir(SPLIT_DIR):
        if not qfile.endswith(".txt"):
            continue
        df, _ = load_query_file(os.path.join(SPLIT_DIR, qfile))
        if df.empty:
            skipped.append(qfile)
            continue
        df_filtered = df[
            (df["identity"] > params["identity"]) &
            (df["alignment_length"] >= params["alignment_length"]) &
            (df["mismatches"] <= params["mismatches"]) &
            (df["evalue"] < params["evalue"])
        ]
        df_sorted = df_filtered.sort_values(by=params["sort_column"], ascending=params["ascending"])
        df_topn = df_sorted.groupby("query").head(params["top_n"])
        total_hits += len(df_topn)
        all_results.append(df_topn)
    if all_results:
        combined = pd.concat(all_results, ignore_index=True)
    else:
        combined = pd.DataFrame()
    return combined, total_hits, skipped

# å‚æ•°è®¾ç½®ï¼ˆä¾§æ ï¼‰
with st.sidebar:
    st.header("ðŸ“Œ ç­›é€‰å‚æ•°è®¾ç½®")
    identity_thresh = st.slider("æœ€å° identity (%)", 0.0, 100.0, 90.0)
    alignment_thresh = st.number_input("æœ€å° alignment_length", value=1000)
    mismatches_thresh = st.number_input("æœ€å¤§ mismatches", value=10)
    evalue_thresh = st.number_input("æœ€å¤§ e-value", value=1e-5, format="%.1e")
    top_n = st.number_input("æ¯ä¸ª query ä¿ç•™å‰ N ä¸ª hits", value=5, min_value=1)
    sort_column = st.selectbox("æŽ’åºå­—æ®µ", ["identity", "alignment_length", "mismatches", "evalue", "bit_score"])
    ascending = st.radio("æŽ’åºæ–¹å¼", ["é™åº", "å‡åº"]) == "å‡åº"

    if st.button("ðŸ”„ æ›´æ–°æ‰€æœ‰ query çš„ç­›é€‰ç»“æžœ"):
        with st.spinner("æ­£åœ¨åˆ†æžæ‰€æœ‰ query æ–‡ä»¶ï¼Œè¯·ç¨å€™..."):
            params = {
                "identity": identity_thresh,
                "alignment_length": alignment_thresh,
                "mismatches": mismatches_thresh,
                "evalue": evalue_thresh,
                "top_n": top_n,
                "sort_column": sort_column,
                "ascending": ascending,
            }
            df_all, total, skipped = apply_filter_to_all_queries(params)
            st.session_state.results_ready = True
            st.session_state.global_result_df = df_all
            st.session_state.total_hits = total
            st.session_state.skipped_queries = skipped
        st.success(f"ðŸŽ¯ å·²å®Œæˆç­›é€‰ï¼šå…±å‘½ä¸­ {total} æ¡è®°å½•")

# å•ä¸ª query å±•ç¤º
selected_file = st.selectbox("é€‰æ‹©ä¸€ä¸ª Query æŸ¥çœ‹å…¶ç»“æžœï¼š", query_files)
df_query, raw_lines = load_query_file(os.path.join(SPLIT_DIR, selected_file))

df_q_filtered = df_query[
    (df_query["identity"] > identity_thresh) &
    (df_query["alignment_length"] >= alignment_thresh) &
    (df_query["mismatches"] <= mismatches_thresh) &
    (df_query["evalue"] < evalue_thresh)
]
df_q_sorted = df_q_filtered.sort_values(by=sort_column, ascending=ascending)
df_q_topn = df_q_sorted.groupby("query").head(top_n)

st.subheader(f"ðŸ”Ž {selected_file} çš„ç­›é€‰ç»“æžœï¼ˆTop {top_n}ï¼‰")
st.dataframe(df_q_topn, use_container_width=True)

# ä¸‹è½½å½“å‰ query
tsv_current = df_q_topn.to_csv(index=False, sep="\t")
st.download_button(
    label="ðŸ“¥ ä¸‹è½½å½“å‰ query çš„ç­›é€‰ç»“æžœ",
    data=tsv_current,
    file_name=f"filtered_{selected_file}",
    mime="text/tab-separated-values"
)

# æ‰€æœ‰ query çš„åˆå¹¶ç»“æžœ
if st.session_state.results_ready:
    st.subheader("ðŸ“Š æ‰€æœ‰ Query çš„åˆå¹¶ç­›é€‰ç»“æžœ")
    st.write(f"âœ… å…±å‘½ä¸­ {st.session_state.total_hits} æ¡è®°å½•")
    st.dataframe(st.session_state.global_result_df.head(50), use_container_width=True)

    all_tsv = st.session_state.global_result_df.to_csv(index=False, sep="\t")
    st.download_button(
        label="ðŸ“¥ ä¸‹è½½æ‰€æœ‰ query çš„ç­›é€‰ç»“æžœï¼ˆåˆå¹¶ï¼‰",
        data=all_tsv,
        file_name="all_filtered_queries.tsv",
        mime="text/tab-separated-values"
    )

    if st.session_state.skipped_queries:
        with st.expander("âš ï¸ è¢«è·³è¿‡çš„ç©º query æ–‡ä»¶åˆ—è¡¨"):
            for q in st.session_state.skipped_queries:
                st.text(q)

# åŽŸå§‹æ³¨é‡Šä¿¡æ¯
with st.expander("ðŸ“ åŽŸå§‹æ³¨é‡Šä¿¡æ¯"):
    for line in raw_lines:
        if line.startswith("#"):
            st.text(line.strip())
